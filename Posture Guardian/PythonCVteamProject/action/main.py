# main.py
# ëª©ì : ì „ì²´ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë¡œì§ (ì¹´ë©”ë¼ ì—°ê²° â†’ í¬ì¦ˆ ë¶„ì„ â†’ ì œìŠ¤ì²˜ ì¸ì‹ â†’ ìƒíƒœ ë¨¸ì‹  â†’ ê²½ê³ /ë¡œê·¸ ê¸°ë¡ â†’ UI ì¶œë ¥)
# Workflow: VideoStreamìœ¼ë¡œ í”„ë ˆì„ ì½ê¸° â†’ MediaPipe Pose/Hands ì²˜ë¦¬ â†’ posture/gesture ë¶„ì„ â†’ StateManagerë¡œ ìƒíƒœ ê´€ë¦¬ â†’ logger/audio_utils í˜¸ì¶œ
import warnings
warnings.filterwarnings("ignore") # ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ê²½ê³ ë¬¸ ë¬´ì‹œ (ì¶œë ¥í•˜ì§€ ì•ŠìŒ)
import cv2, time, numpy as np
import mediapipe as mp
from state_manager import StateManager
from PIL import ImageFont, ImageDraw, Image

# === ëª¨ë“ˆ import ===
# ëª…ì‹œ í˜¸ì¶œ (Pylance ì¸ì‹ ë¬¸ì œ)
from config import (
    POSE_MIN_DETECTION_CONFIDENCE,
    POSE_MIN_TRACKING_CONFIDENCE,
    HANDS_MAX_NUM_HANDS,
    HANDS_MIN_DETECTION_CONFIDENCE,
    HANDS_MIN_TRACKING_CONFIDENCE,
    SOUND_NECK,
    SOUND_LEAN_FORWARD,
    SOUND_LEAN_BACK,
    SOUND_SLOUCH,
    STRETCH_INTERVAL_SEC,
    STRETCH_ALERT_DURATION_SEC,
)
from config import * # posture_log.csv, mp3 ê²½ë¡œ, confidence ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
from video_stream import VideoStream
from gesture_utils import is_victory, is_palm
from posture_analysis import calculate_angle_2d
from logger import setup_log_file, log_event
from audio_utils import play_alert
from state_manager import StateManager


# === 1. ì´ˆê¸°í™” ===

username = ""
password = ""
ip_address = ""
# (ì„±ëŠ¥ ìµœì í™”) ì €í•´ìƒë„ ìŠ¤íŠ¸ë¦¼(stream2) ì‚¬ìš© ê¶Œì¥
rtsp_url = f"rtsp://{username}:{password}@{ip_address}:554/stream2" 

setup_log_file()
cap = VideoStream(rtsp_url).start() 

print("âœ… Camera stream successfully connected.")
print("   ('q' key to quit.)")

# MediaPipe ëª¨ë¸ ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    min_detection_confidence=POSE_MIN_DETECTION_CONFIDENCE,
    min_tracking_confidence=POSE_MIN_TRACKING_CONFIDENCE
)
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    max_num_hands=HANDS_MAX_NUM_HANDS,
    min_detection_confidence=HANDS_MIN_DETECTION_CONFIDENCE,
    min_tracking_confidence=HANDS_MIN_TRACKING_CONFIDENCE
)
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

state = StateManager()
current_stage = 1
FPS = 30

# --- ìŠ¤íŠ¸ë ˆì¹­ ì•Œë¦¼ íƒ€ì´ë¨¸ ì´ˆê¸°í™” ---
stretch_last_time = time.time()
stretch_alert_until = 0.0

stretch_alert_until = 0.0

# === [ì¶”ê°€] í•œê¸€ í°íŠ¸ ë¡œë“œ (PIL) ===
font_path = "c:/Windows/Fonts/malgun.ttf" # ìœˆë„ìš° ë§‘ì€ ê³ ë”•
try:
    # í°íŠ¸ í¬ê¸°ëŠ” 0.7 í°íŠ¸ ìŠ¤ì¼€ì¼ê³¼ ë¹„ìŠ·í•˜ê²Œ 20~25ptë¡œ ì„¤ì •
    font = ImageFont.truetype(font_path, 25)
    print(f"âœ… Korean font '{font_path}' loaded.")
except IOError:
    print(f"ğŸš¨ ERROR: Font not found at '{font_path}'.")
    print("-> Please check font path. Using default (broken) font.")
    font = None # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨

# === [ì¶”ê°€] PILë¡œ í…ìŠ¤íŠ¸ ê·¸ë¦¬ëŠ” í—¬í¼ í•¨ìˆ˜ ===
def draw_text_with_pil(img, text, position, text_color_bgr):
    """
    OpenCV ì´ë¯¸ì§€ë¥¼ ë°›ì•„ PILë¡œ ë³€í™˜ í›„ í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¬ê³ 
    ë‹¤ì‹œ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if font is None: # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ì›ë˜ OpenCV í•¨ìˆ˜ ì‚¬ìš©
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color_bgr, 2)
        return img

    # 1. OpenCV BGR ì´ë¯¸ì§€ë¥¼ RGB PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    
    # 2. Draw ê°ì²´ ìƒì„±
    draw = ImageDraw.Draw(img_pil)
    
    # 3. BGR ìƒ‰ìƒì„ RGBë¡œ ë³€í™˜ (PILì€ RGB ì‚¬ìš©)
    text_color_rgb = (text_color_bgr[2], text_color_bgr[1], text_color_bgr[0])
    
    # 4. í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
    if font:
        draw.text(position, text, font=font, fill=text_color_rgb)
    else:
        draw.text(position, text, fill=text_color_rgb) # ê¸°ë³¸ í°íŠ¸
    
    # 5. PIL RGB ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ BGR OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    return img_cv

# === 2. ë©”ì¸ ë£¨í”„ ===
while True:
    ret, frame = cap.read()
    if not ret or frame is None:
        print("- Waiting for frame...")
        time.sleep(0.5)
        continue

    frame = cv2.flip(frame, 1)
    frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # === [ìˆ˜ì •] í¬ì¦ˆ ê°ì§€ (ìƒì„¸ ê°€ì´ë“œ ì¶”ê°€) ===
    # (ì›ë³¸ ì½”ë“œì˜ ìƒì„¸ ê°€ì´ë“œ ë¡œì§ìœ¼ë¡œ ë³µì›)
    pose_results = pose.process(image_rgb)
    current_pose_ok = False # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
    adjustment_messages = [] # ì¹´ë©”ë¼ ìœ„ì¹˜ ì•ˆë‚´ ë©”ì„¸ì§€ ì´ˆê¸°í™”
    landmarks = None # ëœë“œë§ˆí¬ ì´ˆê¸°í™”

    if pose_results.pose_landmarks:
        landmarks = pose_results.pose_landmarks.landmark
        try: # try-exceptë¡œ ëœë“œë§ˆí¬ ì ‘ê·¼ ë³´í˜¸
            nose = landmarks[mp_pose.PoseLandmark.NOSE.value]
            left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]
            right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]
            left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]
            right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]

            # ëœë“œë§ˆí¬ê°€ í™”ë©´ì— ì˜ ë³´ì´ëŠ”ì§€ (visibility) í™•ì¸
            if all(lm.visibility > 0.7 for lm in [nose, left_shoulder, right_shoulder, left_hip, right_hip]):
                
                # 1. [ë³µì›] ì¤‘ì•™ ì •ë ¬
                shoulder_center_x = (left_shoulder.x + right_shoulder.x) / 2
                if not (0.5 - CENTER_TOLERANCE < shoulder_center_x < 0.5 + CENTER_TOLERANCE):
                    adj_msg = "RIGHT" if shoulder_center_x < 0.5 else "LEFT"
                    adjustment_messages.append(f"[ADJUST] Please move {adj_msg}")
                
                # 2. [ë³µì›] ìƒí•˜/ê±°ë¦¬ ì •ë ¬
                if nose.y < HEAD_ROOM_Y:
                    adjustment_messages.append("[ADJUST] Too close (move DOWN/BACK)")
                elif (left_hip.y > HIP_ROOM_Y or right_hip.y > HIP_ROOM_Y):
                    adjustment_messages.append("[ADJUST] Too far (move UP/CLOSER)")
                
                # 3. [ë³µì›] ëª¨ë“  ì¡°ì • ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ -> ìì„¸ OK
                if not adjustment_messages:
                    current_pose_ok = True
            
            else: 
                adjustment_messages.append("[ERROR] Body not fully visible.")
        except Exception as e:
            adjustment_messages.append("[ERROR] Landmarks not fully detected.")
    else:
        adjustment_messages.append("[GUIDE] Please stand in front of the camera.")

    # ì† ì œìŠ¤ì²˜ ê°ì§€
    detected_gesture = None
    if current_stage in [2, 3]:
        hand_results = hands.process(image_rgb)
        if hand_results.multi_hand_landmarks:
            hand_landmarks = hand_results.multi_hand_landmarks[0]
            if is_palm(hand_landmarks):
                detected_gesture = "PALM"
            elif is_victory(hand_landmarks):
                detected_gesture = "VICTORY"
            mp_drawing.draw_landmarks(
                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,
                mp_drawing_styles.get_default_hand_landmarks_style(),
                mp_drawing_styles.get_default_hand_connections_style()
            )

    # === Stage ë¡œì§ ===
    display_messages = []
    if current_stage == 1:
        # Stage 1: ì¹´ë©”ë¼ ì„¸íŒ… (10ì´ˆ ìœ ì§€)
        if current_pose_ok:
            if state.ok_start_time is None:
                state.ok_start_time = time.time()
            elapsed = time.time() - state.ok_start_time
            if elapsed >= HOLD_DURATION:
                current_stage = 2
                state.reset()
                display_messages = ["[ STAGE 2 ] Show Palm to START"]
            else:
                display_messages.append(f"[ OK ] Hold for {HOLD_DURATION - elapsed:.1f}s")
        else:
            state.ok_start_time = None
            display_messages = adjustment_messages # [ìˆ˜ì •] ìƒì„¸ ê°€ì´ë“œ ë©”ì‹œì§€ í‘œì‹œ

    elif current_stage == 2:
        # Stage 2: ì†ë°”ë‹¥ ì œìŠ¤ì²˜ ëŒ€ê¸° (3ì´ˆ ìœ ì§€)
        display_messages = ["[ STAGE 2 ] Show Palm to START"]
        if detected_gesture == "PALM":
            if state.palm_start_time is None:
                state.palm_start_time = time.time()
            elapsed = time.time() - state.palm_start_time
            if elapsed >= GESTURE_HOLD_DURATION:
                current_stage = 3
                state.reset()
                display_messages = ["[ STAGE 3 ] Monitoring STARTED!"]
            else:
                display_messages.append(f"[ GESTURE ] Hold Palm {GESTURE_HOLD_DURATION - elapsed:.1f}s")
        else:
            state.palm_start_time = None

    elif current_stage == 3:
        # Stage 3: ëª¨ë‹ˆí„°ë§ (ìì„¸ ë¶„ì„ + ë¸Œì´ ì œìŠ¤ì²˜ë¡œ ì¢…ë£Œ)
        display_messages = ["[ STAGE 3 ] Monitoring... (Show ë¸Œì´ Victory to STOP)"]

        if landmarks: # ìì„¸ ê°ì§€ê°€ ì•ˆ ë¼ì„œ current_pose_ok ì‚­ì œ
            # --- ê±°ë¶ëª© ê°ì§€ ---
            try: # [ìˆ˜ì •] ëœë“œë§ˆí¬ ì ‘ê·¼ ë³´í˜¸
                ear = landmarks[mp_pose.PoseLandmark.LEFT_EAR.value]
                shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]
                hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]
                neck_angle = calculate_angle_2d(ear, shoulder, hip)

                if neck_angle and neck_angle < NECK_ANGLE_THRESHOLD:
                    if state.bad_neck_start_time is None:
                        state.bad_neck_start_time = time.time()
                    
                    # ë‚˜ìœ ìì„¸ ì§€ì† ì‹œê°„ (ê±°ë¶ëª©)
                    state.neck_duration +=1
                    neck_duration_sec = state.neck_duration / FPS

                    elapsed = time.time() - state.bad_neck_start_time
                    if elapsed > BAD_POSTURE_DURATION:
                        display_messages.append(f"[WARNING] Turtle Neck! ({neck_angle:.0f}deg, {elapsed:.1f}s)")
                        if not state.neck_warning_triggered:
                            log_event("Turtle_Neck", neck_angle)
                            state.neck_warning_triggered = True
                            print(f"Neck angle  : {neck_angle:.1f}   (Held {neck_duration_sec:.1f}s)")
                            play_alert(SOUND_NECK)
                else:
                    state.bad_neck_start_time = None
                    state.neck_warning_triggered = False

                # --- í—ˆë¦¬ ê¸°ìš¸ì„ ê°ì§€ ---
                dy = -(shoulder.y - hip.y)
                dx = shoulder.x - hip.x
                lean_angle = np.degrees(np.arctan2(dy, dx))
                if not (LEAN_ANGLE_THRESHOLD_LOW < lean_angle < LEAN_ANGLE_THRESHOLD_HIGH):
                    if state.bad_lean_start_time is None:
                        state.bad_lean_start_time = time.time()

                    # ë‚˜ìœ ìì„¸ ì§€ì† ì‹œê°„ (ê¸°ëŒ„ ìì„¸ ì•/ë’¤)
                    state.lean_duration +=1
                    lean_duration_sec = state.lean_duration / FPS

                    elapsed = time.time() - state.bad_lean_start_time
                    if elapsed > BAD_POSTURE_DURATION:
                        if lean_angle > LEAN_ANGLE_THRESHOLD_HIGH:
                            msg = "Leaning Forward!"
                            sound = SOUND_LEAN_FORWARD
                        else:
                            msg = "Leaning Back!"
                            sound = SOUND_LEAN_BACK
                        display_messages.append(f"[WARNING] {msg} ({lean_angle:.0f} deg, {elapsed: .1f}s)")
                        if not state.lean_warning_triggered:
                            log_event("Leaning", lean_angle)
                            state.lean_warning_triggered = True
                            print(f"Lean angle  : {lean_angle:.1f}   (Held {lean_duration_sec:.1f}s)")
                            play_alert(sound)
                else:
                    state.bad_lean_start_time = None
                    state.lean_warning_triggered = False

                # --- êµ¬ë¶€ì • ê°ì§€ ---
                torso_h = abs(shoulder.x - hip.x)
                torso_v = abs(shoulder.y - hip.y)
                if torso_v > 0.01:
                    slouch_ratio = torso_h / torso_v
                    if slouch_ratio > SLOUCH_RATIO_THRESHOLD:
                        if state.bad_slouch_start_time is None:
                            state.bad_slouch_start_time = time.time()

                        # ë‚˜ìœ ìì„¸ ì§€ì† ì‹œê°„ (êµ¬ë¶€ì •..)
                        state.slouch_duration +=1
                        slouch_duration_sec = state.slouch_duration / FPS

                        elapsed = time.time() - state.bad_slouch_start_time
                        if elapsed > BAD_POSTURE_DURATION:
                            display_messages.append(f"[WARNING] Slouching! (ratio={slouch_ratio:.2f}, {elapsed: .1f}s)")
                            if not state.slouch_warning_triggered:
                                log_event("Slouching", slouch_ratio)
                                state.slouch_warning_triggered = True
                                print(f"Slouch ratio: {slouch_ratio:.2f}   (Held {slouch_duration_sec:.2f}s)")
                                play_alert(SOUND_SLOUCH)
                    else:
                        state.bad_slouch_start_time = None
                        state.slouch_warning_triggered = False
            
            except Exception as e:
                # Stage 3ì—ì„œ ëœë“œë§ˆí¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
                display_messages.append("[ERROR] Angle calculation failed.")
                
        # --- [ìŠ¤íŠ¸ë ˆì¹­ ë¦¬ë§ˆì¸ë”: í…ŒìŠ¤íŠ¸ìš© 1ë¶„ ì£¼ê¸°] ---
        now = time.time()
        if now - stretch_last_time >= STRETCH_INTERVAL_SEC:
            stretch_last_time = now
            stretch_alert_until = now + STRETCH_ALERT_DURATION_SEC
            print("[STRETCH] It's time to stretch your body!")


        # --- ë¸Œì´ ì œìŠ¤ì²˜ë¡œ ì¢…ë£Œ ---
        if detected_gesture == "VICTORY":
            if state.fist_start_time is None:
                state.fist_start_time = time.time()
            elapsed = time.time() - state.fist_start_time
            if elapsed >= GESTURE_HOLD_DURATION:
                current_stage = 1
                state.reset()
                display_messages = ["[ RESET ] Monitoring stopped."]
            else:
                # âœ… [ì¶”ê°€] ë¸Œì´ ì œìŠ¤ì²˜ ì¹´ìš´íŠ¸ë‹¤ìš´ ë©”ì‹œì§€
                display_messages.append(f"[ GESTURE ] Hold Victory {GESTURE_HOLD_DURATION - elapsed:.1f}s")
        else:
            state.fist_start_time = None

    # === [ì‹ ê·œ] ê³µí†µ ë¦¬ì…‹ ë¡œì§ (Safety Reset) ===
    # 2/3ë‹¨ê³„ì¼ ë•Œ, ìì„¸ê°€ 30ì´ˆ ì´ìƒ ì´íƒˆí•˜ë©´ 1ë‹¨ê³„ë¡œ ê°•ì œ ë¦¬ì…‹
    if current_stage == 2 or current_stage == 3:
        if not current_pose_ok:
            if state.not_ok_start_time is None: 
                state.not_ok_start_time = time.time()
            elapsed_not_ok = time.time() - state.not_ok_start_time
            remaining_time = RESET_DURATION - elapsed_not_ok
            
            if remaining_time <= 0:
                # 30ì´ˆ ì´íƒˆ -> 1ë‹¨ê³„ë¡œ ë¦¬ì…‹
                current_stage = 1
                state.reset() # StateManagerë¡œ ëª¨ë“  íƒ€ì´ë¨¸ ë¦¬ì…‹
                display_messages = ["[ RESET ] Position lost. Returning to setup..."]
                # ìŠ¤íŠ¸ë ˆì¹­ íƒ€ì´ë¨¸ë„ ë¦¬ì…‹
                stretch_last_time = time.time()
                stretch_alert_until = 0.0
            else:
                display_messages.append(f"[ WARNING ] Position lost. Reset in {remaining_time:.0f}s")
                # (ì¤‘ìš”) ì´íƒˆ ì‚¬ìœ ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ adjustment_messagesë¥¼ ì¶”ê°€
                display_messages.extend(adjustment_messages) 
        else:
            # ìì„¸ê°€ ì •ìƒì´ë©´ ë¦¬ì…‹ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
            if state.not_ok_start_time is not None: 
                state.not_ok_start_time = None

    # --- [ìŠ¤íŠ¸ë ˆì¹­ ì•Œë¦¼ í‘œì‹œ] ---
    if time.time() < stretch_alert_until:
        h, w = frame.shape[:2]
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 80), (0, 0, 0), -1)
        alpha = 0.5
        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)

        # [ìˆ˜ì •] í•œê¸€ ë©”ì‹œì§€ë¡œ ë³€ê²½ ë° PIL í•¨ìˆ˜ ì‚¬ìš©
        stretch_msg = "ìŠ¤íŠ¸ë ˆì¹­ ì‹œê°„ì…ë‹ˆë‹¤!" 
        text_color_bgr = (255, 255, 255) # í°ìƒ‰ (BGR)
        
        # (ì£¼ì˜: PIL í°íŠ¸ ê¸°ì¤€ì ì´ ì•½ê°„ ë‹¬ë¼ì„œ (20, 50) -> (20, 40)ìœ¼ë¡œ yì¢Œí‘œ ì¡°ì •)
        frame = draw_text_with_pil(frame, stretch_msg, (20, 40), text_color_bgr)
        
    # UI ë©”ì‹œì§€ ì¶œë ¥
    # y_offset = 30  <- (ì´ ë³€ìˆ˜ëŠ” PIL í—¬í¼ í•¨ìˆ˜ë¥¼ ì“°ë©´ í•„ìš” ì—†ì–´ì§)
    for i, msg in enumerate(display_messages):
        # [ìˆ˜ì •] ë©”ì‹œì§€ ìƒ‰ìƒ ë³€ê²½ ë¡œì§ ì¶”ê°€ (ì´ê±´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        color = (0, 255, 0) # ê¸°ë³¸ ë…¹ìƒ‰ (OK)
        if "ERROR" in msg or "GUIDE" in msg: color = (0, 0, 255) # ì ìƒ‰
        elif "ADJUST" in msg: color = (0, 165, 255) # ì£¼í™©
        elif "WARNING" in msg or "RESET" in msg: color = (0, 69, 255) # ì§„í•œ ì£¼í™©
        elif "Hold" in msg: color = (255, 255, 0) # ì²­ë¡ìƒ‰ (ëŒ€ê¸°)

        # [ìˆ˜ì •] cv2.putText ëŒ€ì‹  PIL í—¬í¼ í•¨ìˆ˜ ì‚¬ìš©
        # (ì£¼ì˜: PILì€ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ frameì„ ë®ì–´ì¨ì•¼ í•¨)
        # (PIL í°íŠ¸ ê¸°ì¤€ì ì´ ì•½ê°„ ë‹¤ë¥´ë¯€ë¡œ y ì¢Œí‘œë¥¼ ì‚´ì§ ì¡°ì • (ì˜ˆ: 25 + i * 35))
        frame = draw_text_with_pil(frame, msg, (20, 25 + i * 35), color)

    if pose_results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    cv2.imshow('Posture Guardian - Project (Voice Enabled)', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# === ì¢…ë£Œ ì²˜ë¦¬ ===
print("Shutting down...")
pose.close()
hands.close()
cap.stop()
cv2.destroyAllWindows()